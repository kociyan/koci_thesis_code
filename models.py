# -*- coding: utf-8 -*-
"""Models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14GaCBfJsp9Q38-YQ9SIjUpPL4EbKs7C6
"""

import pandas as pd
import numpy as np
import io
from google.colab import files
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

print("Please upload train_set.xlsx")
uploaded_train = files.upload()
train_file_name = list(uploaded_train.keys())[0]
train_df = pd.read_excel(io.BytesIO(uploaded_train[train_file_name]))
print(f"Successfully loaded {train_file_name}")

print("\nPlease upload test_set.xlsx")
uploaded_test = files.upload()
test_file_name = list(uploaded_test.keys())[0]
test_df = pd.read_excel(io.BytesIO(uploaded_test[test_file_name]))
print(f"Successfully loaded {test_file_name}")

target_vars = ['view_count', 'like_count', 'comment_count']
categorical_features = ['latency_gap', 'categorical_time_group', 'month', 'local_weekday', 'holiday', 'region', 'category']

combined_df = pd.concat([train_df[categorical_features], test_df[categorical_features]], ignore_index=True)
combined_encoded = pd.get_dummies(combined_df, columns=categorical_features, drop_first=True)

X_train_encoded = combined_encoded.iloc[:len(train_df)]
X_test_encoded = combined_encoded.iloc[len(train_df):]

for target in target_vars:
    print("-" * 50)
    print(f"Building Model for Target: {target}")
    print("-" * 50)

    y_train = np.log1p(train_df[target])
    y_test = np.log1p(test_df[target])

    lr_model = LinearRegression()
    lr_model.fit(X_train_encoded, y_train)

    y_pred = lr_model.predict(X_test_encoded)

    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    print(f"Evaluation Metrics for log_{target}:")
    print(f"  Mean Absolute Error (MAE):    {mae:.4f}")
    print(f"  Mean Squared Error (MSE):     {mse:.4f}")
    print(f"  Root Mean Squared Error (RMSE): {rmse:.4f}")
    print(f"  R-squared (R2):               {r2:.4f}\n")

import pandas as pd
import numpy as np
import io
from google.colab import files
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

print("Please upload train_set.xlsx")
uploaded_train = files.upload()
train_file_name = list(uploaded_train.keys())[0]
train_df = pd.read_excel(io.BytesIO(uploaded_train[train_file_name]))
print(f"Successfully loaded {train_file_name}")

print("\nPlease upload test_set.xlsx")
uploaded_test = files.upload()
test_file_name = list(uploaded_test.keys())[0]
test_df = pd.read_excel(io.BytesIO(uploaded_test[test_file_name]))
print(f"Successfully loaded {test_file_name}")

target_vars = ['view_count', 'like_count', 'comment_count']
categorical_features = ['latency_gap', 'month', 'local_weekday', 'holiday', 'region', 'category']
numerical_features = ['hour_sin', 'hour_cos']

X_train_cat = pd.get_dummies(train_df[categorical_features], drop_first=True)
X_test_cat = pd.get_dummies(test_df[categorical_features], drop_first=True)

X_train = pd.concat([train_df[numerical_features], X_train_cat], axis=1)
X_test = pd.concat([test_df[numerical_features], X_test_cat], axis=1)

train_cols = X_train.columns
test_cols = X_test.columns
missing_in_test = set(train_cols) - set(test_cols)
for c in missing_in_test:
    X_test[c] = 0
missing_in_train = set(test_cols) - set(train_cols)
for c in missing_in_train:
    X_train[c] = 0
X_test = X_test[train_cols]

param_grid_dt = {
    'max_depth': [5, 10, 15, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

for target in target_vars:
    print("-" * 50)
    print(f"Building Model for Target: {target}")
    print("-" * 50)

    y_train = np.log1p(train_df[target])
    y_test = np.log1p(test_df[target])

    dt = DecisionTreeRegressor(random_state=42)
    grid_search = GridSearchCV(
        estimator=dt,
        param_grid=param_grid_dt,
        cv=5,
        scoring='neg_mean_squared_error',
        verbose=1,
        n_jobs=-1
    )

    print("Starting GridSearchCV for Decision Tree...")
    grid_search.fit(X_train, y_train)
    print("GridSearchCV finished.")

    best_dt = grid_search.best_estimator_
    print(f"\nBest Hyperparameters: {grid_search.best_params_}")

    y_pred = best_dt.predict(X_test)

    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    print(f"\nEvaluation Metrics for log_{target}:")
    print(f"  Mean Absolute Error (MAE):    {mae:.4f}")
    print(f"  Mean Squared Error (MSE):     {mse:.4f}")
    print(f"  Root Mean Squared Error (RMSE): {rmse:.4f}")
    print(f"  R-squared (R2):               {r2:.4f}\n")

import pandas as pd
import numpy as np
import io
from google.colab import files
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

print("Please upload train_set.xlsx")
uploaded_train = files.upload()
train_file_name = list(uploaded_train.keys())[0]
train_df = pd.read_excel(io.BytesIO(uploaded_train[train_file_name]))
print(f"Successfully loaded {train_file_name}")

print("\nPlease upload test_set.xlsx")
uploaded_test = files.upload()
test_file_name = list(uploaded_test.keys())[0]
test_df = pd.read_excel(io.BytesIO(uploaded_test[test_file_name]))
print(f"Successfully loaded {test_file_name}")

target_vars = ['view_count', 'like_count', 'comment_count']
categorical_features = ['latency_gap', 'month', 'local_weekday', 'holiday', 'region', 'category']
numerical_features = ['hour_sin', 'hour_cos']

X_train_cat = pd.get_dummies(train_df[categorical_features], drop_first=True)
X_test_cat = pd.get_dummies(test_df[categorical_features], drop_first=True)

X_train = pd.concat([train_df[numerical_features], X_train_cat], axis=1)
X_test = pd.concat([test_df[numerical_features], X_test_cat], axis=1)

train_cols = X_train.columns
test_cols = X_test.columns
missing_in_test = set(train_cols) - set(test_cols)
for c in missing_in_test:
    X_test[c] = 0
missing_in_train = set(test_cols) - set(train_cols)
for c in missing_in_train:
    X_train[c] = 0
X_test = X_test[train_cols]

param_grid_rf = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, 30],
    'min_samples_split': [2, 6],
    'min_samples_leaf': [1, 2],
    'max_features': ['sqrt', 'log2']
}

for target in target_vars:
    print("-" * 50)
    print(f"Building Model for Target: {target}")
    print("-" * 50)

    y_train = np.log1p(train_df[target])
    y_test = np.log1p(test_df[target])

    rf = RandomForestRegressor(random_state=42)
    grid_search = GridSearchCV(
        estimator=rf,
        param_grid=param_grid_rf,
        cv=5,
        scoring='neg_mean_squared_error',
        verbose=1,
        n_jobs=-1
    )

    print("Starting GridSearchCV for Random Forest...")
    grid_search.fit(X_train, y_train)
    print("GridSearchCV finished.")

    best_rf = grid_search.best_estimator_
    print(f"\nBest Hyperparameters: {grid_search.best_params_}")

    y_pred = best_rf.predict(X_test)

    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    print(f"\nEvaluation Metrics for log_{target}:")
    print(f"  Mean Absolute Error (MAE):    {mae:.4f}")
    print(f"  Mean Squared Error (MSE):     {mse:.4f}")
    print(f"  Root Mean Squared Error (RMSE): {rmse:.4f}")
    print(f"  R-squared (R2):               {r2:.4f}\n")

import pandas as pd
import numpy as np
import io
from google.colab import files
import xgboost as xgb
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

print("Please upload train_set.xlsx")
uploaded_train = files.upload()
train_file_name = list(uploaded_train.keys())[0]
train_df = pd.read_excel(io.BytesIO(uploaded_train[train_file_name]))
print(f"Successfully loaded {train_file_name}")

print("\nPlease upload test_set.xlsx")
uploaded_test = files.upload()
test_file_name = list(uploaded_test.keys())[0]
test_df = pd.read_excel(io.BytesIO(uploaded_test[test_file_name]))
print(f"Successfully loaded {test_file_name}")

target_vars = ['view_count', 'like_count', 'comment_count']
categorical_features = ['latency_gap', 'month', 'local_weekday', 'holiday', 'region', 'category']
numerical_features = ['hour_sin', 'hour_cos']

X_train_cat = pd.get_dummies(train_df[categorical_features], drop_first=True)
X_test_cat = pd.get_dummies(test_df[categorical_features], drop_first=True)

X_train = pd.concat([train_df[numerical_features], X_train_cat], axis=1)
X_test = pd.concat([test_df[numerical_features], X_test_cat], axis=1)

train_cols = X_train.columns
test_cols = X_test.columns
missing_in_test = set(train_cols) - set(test_cols)
for c in missing_in_test:
    X_test[c] = 0
missing_in_train = set(test_cols) - set(train_cols)
for c in missing_in_train:
    X_train[c] = 0
X_test = X_test[train_cols]

param_grid_xgb = {
    'n_estimators': [100, 200, 500],
    'learning_rate': [0.01, 0.05, 0.1],
    'max_depth': [6, 7, 8],
    'subsample': [0.7, 0.8, 0.9],
    'colsample_bytree': [0.7, 0.8, 0.9]
}

for target in target_vars:
    print("-" * 50)
    print(f"Building Model for Target: {target}")
    print("-" * 50)

    y_train = np.log1p(train_df[target])
    y_test = np.log1p(test_df[target])

    xgbr = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
    grid_search = GridSearchCV(
        estimator=xgbr,
        param_grid=param_grid_xgb,
        cv=5,
        scoring='neg_mean_squared_error',
        verbose=1,
        n_jobs=-1
    )

    print("Starting GridSearchCV for XGBoost...")
    grid_search.fit(X_train, y_train)
    print("GridSearchCV finished.")

    best_xgb = grid_search.best_estimator_
    print(f"\nBest Hyperparameters: {grid_search.best_params_}")

    y_pred = best_xgb.predict(X_test)

    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    print(f"\nEvaluation Metrics for log_{target}:")
    print(f"  Mean Absolute Error (MAE):    {mae:.4f}")
    print(f"  Mean Squared Error (MSE):     {mse:.4f}")
    print(f"  Root Mean Squared Error (RMSE): {rmse:.4f}")
    print(f"  R-squared (R2):               {r2:.4f}\n")